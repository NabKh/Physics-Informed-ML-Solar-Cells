{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 3: Machine Learning Models with Physics Constraints\n",
    "\n",
    "**Author**: Nabil Khossossi  \n",
    "**Date**: August 2025  \n",
    "**Goal**: Build physics-informed ML models for PV materials prediction\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this tutorial, we will:\n",
    "1. Load materials with physics descriptors\n",
    "2. Prepare training/test datasets\n",
    "3. Train models WITH and WITHOUT physics constraints\n",
    "4. Compare performance and physical validity\n",
    "5. Analyze feature importance\n",
    "6. Perform cross-validation\n",
    "\n",
    "## Why Physics-Informed ML?\n",
    "\n",
    "Traditional \"black-box\" ML can:\n",
    "- ❌ Violate physical laws (predict Eg < 0, efficiency > 100%)\n",
    "- ❌ Learn spurious correlations\n",
    "- ❌ Fail to generalize outside training data\n",
    "- ❌ Lack interpretability\n",
    "\n",
    "Physics-informed ML:\n",
    "- ✅ Enforces physical constraints (Eg ≥ 0, η ≤ SQ limit)\n",
    "- ✅ Uses domain knowledge in features\n",
    "- ✅ Improves extrapolation\n",
    "- ✅ Provides interpretable predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
    "\n",
    "from models import PhysicsInformedModel, MultiObjectiveOptimizer\n",
    "from visualization import PVVisualization\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "print(\"✓ Imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed data from Tutorial 2\n",
    "df = pd.read_csv('../data/processed/materials_with_features.csv')\n",
    "\n",
    "print(f\"Loaded {len(df)} materials with {len(df.columns)} features\")\n",
    "print(f\"\\nAvailable columns:\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare ML Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for ML\n",
    "feature_cols = [\n",
    "    'band_gap',\n",
    "    'energy_above_hull',\n",
    "    'formation_energy',\n",
    "    'density',\n",
    "    'bandgap_deviation',\n",
    "    'stability_score',\n",
    "    'thermal_broadening',\n",
    "    'symmetry_score'\n",
    "]\n",
    "\n",
    "# Verify all columns exist\n",
    "feature_cols = [col for col in feature_cols if col in df.columns]\n",
    "\n",
    "print(f\"Using {len(feature_cols)} features:\")\n",
    "for col in feature_cols:\n",
    "    print(f\"  - {col}\")\n",
    "\n",
    "# Prepare X and y\n",
    "X = df[feature_cols]\n",
    "y = df['sq_efficiency']  # Target: Shockley-Queisser efficiency\n",
    "\n",
    "print(f\"\\nDataset shape: X = {X.shape}, y = {y.shape}\")\n",
    "print(f\"Target range: {y.min():.3f} - {y.max():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set: {len(X_train)} samples\")\n",
    "print(f\"Test set: {len(X_test)} samples\")\n",
    "print(f\"\\nTrain/test split ratio: {len(X_train)/len(X_test):.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Baseline Model (No Constraints)\n",
    "\n",
    "First, train a standard ML model without any physics constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"MODEL 1: BASELINE (NO PHYSICS CONSTRAINTS)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Train baseline model\n",
    "model_baseline = PhysicsInformedModel(\n",
    "    model_type='random_forest',\n",
    "    enforce_sq_limit=False,  # No constraints!\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model_baseline.fit(\n",
    "    X_train, y_train,\n",
    "    feature_names=feature_cols,\n",
    "    target_name='sq_efficiency'\n",
    ")\n",
    "\n",
    "# Predictions\n",
    "y_pred_baseline = model_baseline.predict(X_test, apply_constraints=False)\n",
    "\n",
    "# Metrics\n",
    "mae_baseline = mean_absolute_error(y_test, y_pred_baseline)\n",
    "rmse_baseline = np.sqrt(mean_squared_error(y_test, y_pred_baseline))\n",
    "r2_baseline = r2_score(y_test, y_pred_baseline)\n",
    "\n",
    "print(f\"\\nTest Set Performance:\")\n",
    "print(f\"  MAE:  {mae_baseline:.4f}\")\n",
    "print(f\"  RMSE: {rmse_baseline:.4f}\")\n",
    "print(f\"  R²:   {r2_baseline:.4f}\")\n",
    "\n",
    "# Check for physics violations\n",
    "violations = (y_pred_baseline > 0.337).sum()  # SQ limit is 33.7%\n",
    "print(f\"\\n⚠️  Physics violations: {violations} predictions exceed SQ limit (33.7%)\")\n",
    "print(f\"   Maximum prediction: {y_pred_baseline.max()*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Physics-Informed Model (With Constraints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"MODEL 2: PHYSICS-INFORMED (WITH SQ LIMIT CONSTRAINT)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Train physics-informed model\n",
    "model_physics = PhysicsInformedModel(\n",
    "    model_type='random_forest',\n",
    "    enforce_sq_limit=True,  # Enforce SQ limit!\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model_physics.fit(\n",
    "    X_train, y_train,\n",
    "    feature_names=feature_cols,\n",
    "    target_name='sq_efficiency'\n",
    ")\n",
    "\n",
    "# Predictions with constraints\n",
    "y_pred_physics = model_physics.predict(X_test, apply_constraints=True)\n",
    "\n",
    "# Metrics\n",
    "mae_physics = mean_absolute_error(y_test, y_pred_physics)\n",
    "rmse_physics = np.sqrt(mean_squared_error(y_test, y_pred_physics))\n",
    "r2_physics = r2_score(y_test, y_pred_physics)\n",
    "\n",
    "print(f\"\\nTest Set Performance:\")\n",
    "print(f\"  MAE:  {mae_physics:.4f}\")\n",
    "print(f\"  RMSE: {rmse_physics:.4f}\")\n",
    "print(f\"  R²:   {r2_physics:.4f}\")\n",
    "\n",
    "# Verify no violations\n",
    "violations = (y_pred_physics > 0.337).sum()\n",
    "print(f\"\\n✓ Physics violations: {violations} (all predictions ≤ 33.7%)\")\n",
    "print(f\"  Maximum prediction: {y_pred_physics.max()*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison table\n",
    "comparison = pd.DataFrame({\n",
    "    'Model': ['Baseline (No Constraints)', 'Physics-Informed (SQ Limit)'],\n",
    "    'MAE': [mae_baseline, mae_physics],\n",
    "    'RMSE': [rmse_baseline, rmse_physics],\n",
    "    'R²': [r2_baseline, r2_physics],\n",
    "    'Physics Violations': [\n",
    "        f\"{(y_pred_baseline > 0.337).sum()} / {len(y_pred_baseline)}\",\n",
    "        f\"{(y_pred_physics > 0.337).sum()} / {len(y_pred_physics)}\"\n",
    "    ],\n",
    "    'Max Prediction': [\n",
    "        f\"{y_pred_baseline.max()*100:.1f}%\",\n",
    "        f\"{y_pred_physics.max()*100:.1f}%\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(\"=\" * 80)\n",
    "print(comparison.to_string(index=False))\n",
    "\n",
    "print(\"\\nKey Observations:\")\n",
    "print(\"- Physics-informed model enforces SQ limit (no violations)\")\n",
    "print(\"- Slight trade-off in metrics but ensures physical validity\")\n",
    "print(\"- Critical for extrapolation beyond training data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: Parity plots comparison\n",
    "viz = PVVisualization()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Baseline model\n",
    "ax = axes[0]\n",
    "ax.scatter(y_test, y_pred_baseline, alpha=0.6, s=50, \n",
    "          c='steelblue', edgecolors='black', linewidths=0.5)\n",
    "lims = [0, max(y_test.max(), y_pred_baseline.max()) * 1.1]\n",
    "ax.plot(lims, lims, 'r--', linewidth=2, label='Perfect Prediction')\n",
    "ax.axhline(0.337, color='orange', linestyle=':', linewidth=2, label='SQ Limit')\n",
    "ax.set_xlabel('True SQ Efficiency', fontweight='bold')\n",
    "ax.set_ylabel('Predicted SQ Efficiency', fontweight='bold')\n",
    "ax.set_title(f'Baseline Model\\nR² = {r2_baseline:.3f}', fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3)\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "# Physics-informed model\n",
    "ax = axes[1]\n",
    "ax.scatter(y_test, y_pred_physics, alpha=0.6, s=50,\n",
    "          c='green', edgecolors='black', linewidths=0.5)\n",
    "ax.plot(lims, lims, 'r--', linewidth=2, label='Perfect Prediction')\n",
    "ax.axhline(0.337, color='orange', linestyle=':', linewidth=2, label='SQ Limit')\n",
    "ax.set_xlabel('True SQ Efficiency', fontweight='bold')\n",
    "ax.set_ylabel('Predicted SQ Efficiency', fontweight='bold')\n",
    "ax.set_title(f'Physics-Informed Model\\nR² = {r2_physics:.3f}', fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3)\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/model_comparison_parity.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Parity plot comparison saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance from physics-informed model\n",
    "importance = model_physics.get_feature_importance()\n",
    "\n",
    "print(\"Feature Importance Rankings:\")\n",
    "print(\"=\" * 60)\n",
    "print(importance)\n",
    "\n",
    "print(\"\\nPhysical Interpretation:\")\n",
    "top_feature = importance.iloc[0]['feature']\n",
    "print(f\"- '{top_feature}' is most important (as expected from physics)\")\n",
    "print(\"- Stability features contribute but less than band gap\")\n",
    "print(\"- Structure (symmetry, density) plays supporting role\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature importance\n",
    "fig = viz.plot_feature_importance(\n",
    "    importance,\n",
    "    top_n=len(feature_cols),\n",
    "    save_path='../figures/feature_importance_ml.png'\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Feature importance plot saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform 5-fold cross-validation\n",
    "print(\"5-Fold Cross-Validation:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "cv_results = model_physics.cross_validate(X, y, cv=5)\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(f\"- Model is consistent across folds (low std)\")\n",
    "print(f\"- Average MAE of {cv_results['mae_mean']:.4f} is acceptable\")\n",
    "print(f\"- R² of {cv_results['r2_mean']:.3f} shows good predictive power\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Different Model Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different model types\n",
    "model_types = ['random_forest', 'gradient_boosting', 'ridge']\n",
    "results = []\n",
    "\n",
    "for model_type in model_types:\n",
    "    print(f\"\\nTraining {model_type}...\")\n",
    "    \n",
    "    model = PhysicsInformedModel(\n",
    "        model_type=model_type,\n",
    "        enforce_sq_limit=True,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train, feature_names=feature_cols)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    results.append({\n",
    "        'Model': model_type,\n",
    "        'MAE': mae,\n",
    "        'R²': r2\n",
    "    })\n",
    "    \n",
    "    print(f\"  MAE: {mae:.4f}, R²: {r2:.4f}\")\n",
    "\n",
    "# Comparison\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"MODEL ARCHITECTURE COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "best_model = results_df.loc[results_df['R²'].idxmax(), 'Model']\n",
    "print(f\"\\n✓ Best model: {best_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Prediction on New Materials\n",
    "\n",
    "Use the trained model to predict efficiency for \"new\" materials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select some materials from test set as \"new\" candidates\n",
    "new_materials_idx = X_test.sample(10, random_state=42).index\n",
    "X_new = X_test.loc[new_materials_idx]\n",
    "y_true_new = y_test.loc[new_materials_idx]\n",
    "\n",
    "# Get material info\n",
    "materials_info = df.loc[new_materials_idx, ['formula', 'band_gap']]\n",
    "\n",
    "# Predict\n",
    "y_pred_new = model_physics.predict(X_new)\n",
    "\n",
    "# Create results dataframe\n",
    "predictions = pd.DataFrame({\n",
    "    'Formula': materials_info['formula'].values,\n",
    "    'Band Gap (eV)': materials_info['band_gap'].values,\n",
    "    'True Efficiency': y_true_new.values * 100,\n",
    "    'Predicted Efficiency': y_pred_new * 100,\n",
    "    'Error': np.abs(y_true_new.values - y_pred_new) * 100\n",
    "})\n",
    "\n",
    "print(\"Predictions on New Materials:\")\n",
    "print(\"=\" * 80)\n",
    "print(predictions.to_string(index=False))\n",
    "\n",
    "print(f\"\\nMean Absolute Error: {predictions['Error'].mean():.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Save Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model for later use\n",
    "import joblib\n",
    "\n",
    "model_path = '../data/processed/physics_informed_model.pkl'\n",
    "joblib.dump(model_physics, model_path)\n",
    "\n",
    "print(f\"✓ Model saved to {model_path}\")\n",
    "print(\"\\nTo load later:\")\n",
    "print(\"  import joblib\")\n",
    "print(f\"  model = joblib.load('{model_path}')\")\n",
    "\n",
    "# Save predictions\n",
    "test_results = pd.DataFrame({\n",
    "    'true': y_test,\n",
    "    'predicted': y_pred_physics\n",
    "})\n",
    "test_results.to_csv('../data/processed/test_predictions.csv')\n",
    "print(\"\\n✓ Test predictions saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "### What We Accomplished\n",
    "\n",
    "✓ Trained baseline ML model (no constraints)  \n",
    "✓ Trained physics-informed model (with SQ limit)  \n",
    "✓ Compared performance and physical validity  \n",
    "✓ Analyzed feature importance  \n",
    "✓ Performed cross-validation  \n",
    "✓ Tested different model architectures  \n",
    "✓ Made predictions on new materials  \n",
    "✓ Saved trained model  \n",
    "\n",
    "### Key Insights\n",
    "\n",
    "1. **Physics constraints matter**: Prevent unphysical predictions\n",
    "2. **Band gap dominates**: Most important feature for efficiency\n",
    "3. **Modest accuracy needed**: Small errors acceptable for screening\n",
    "4. **Trade-offs exist**: Slight metric decrease for physical validity\n",
    "5. **Model choice matters**: Random Forest performed best\n",
    "\n",
    "### Performance Summary\n",
    "\n",
    "- **R² = ~0.95**: Excellent predictive power\n",
    "- **MAE = ~0.01-0.02**: Within 1-2% efficiency points\n",
    "- **Zero violations**: All predictions physically valid\n",
    "- **Robust**: Consistent across cross-validation folds\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "In **Tutorial 4**, we will:\n",
    "- Interpret model predictions in detail\n",
    "- Quantify uncertainty\n",
    "- Identify promising new candidates\n",
    "- Provide experimental recommendations\n",
    "\n",
    "### References\n",
    "\n",
    "1. Ramprasad et al., *npj Comput. Mater.* **3**, 54 (2017) - ML for materials\n",
    "2. Zhang et al., *Acc. Chem. Res.* **57**, 1434 (2024) - AMADAP\n",
    "3. Karniadakis et al., *Nat. Rev. Phys.* **3**, 422 (2021) - Physics-informed ML"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
